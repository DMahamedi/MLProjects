{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "886cc206-c8ed-4025-9bda-1ea176cc201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import normalize\n",
    "import sklearn.datasets as datasets\n",
    "import openml as oml\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ec0874-3bbf-4249-b990-8934a0ad24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPredict(weights, x): #function that makes the models predictions based on input data\n",
    "    ans = np.dot(x, weights)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc164dba-970e-420d-9470-781bd92b6ba9",
   "metadata": {},
   "source": [
    "Data normalization function, to predict values which are typically large from having an outsized effect on the model (and scaling all data points to have norm less than or equal to 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72a6d0c-2d5e-4ff7-b85c-d5c5a1cf9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(X):\n",
    "    min_vals, max_vals = X.min(axis=0), X.max(axis=0)\n",
    "    scaled_data = (X - min_vals) / (max_vals - min_vals)\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90335668-7978-4454-80fe-281e966369b4",
   "metadata": {},
   "source": [
    "Function to calculate the loss. In this case we are using the Mean Squared Error (MSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c68b14-1724-4b43-87fb-7f7deeb1068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanSquaredLoss(y_train, modelPredictions):\n",
    "    diff = ((y_train - modelPredictions) ** 2)\n",
    "    ans = diff.sum() / len(diff)\n",
    "    print(ans / len(diff))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29062327-3b53-4789-9f03-e18132d5caff",
   "metadata": {},
   "source": [
    "Accuracy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8fa240-7f2c-4723-b8ad-11930b12f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAccuracy(y,predictions):\n",
    "    residualSumSquares = ((y - predictions) ** 2).sum()\n",
    "    totalSumSquares = ((y - y.mean()) ** 2).sum()\n",
    "    accuracy = 1 - (residualSumSquares / totalSumSquares)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2db001-4f09-43dd-be24-9bce79eb3428",
   "metadata": {},
   "source": [
    "Below is the gradient function, which uses derivatives on the MSE to increase the models accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7382549b-f7f6-4e53-8aeb-cf44ab9d97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanSquaredGradient(x_train, y_train, modelPredictions):\n",
    "    N = len(y_train)\n",
    "    errors = y_train - modelPredictions\n",
    "    gradient = -2 * np.dot(errors, x_train) / N   \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261b80f-22c2-4af3-9911-8af6602046bc",
   "metadata": {},
   "source": [
    "This is the function that actually trains the model. It takes in the training data, with the learning rate and number of iterations set to be optional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232e3e64-8eb2-499f-aec4-8356c067433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(x_train, y_train, learningRate = 0.04, numIterations = 1000):\n",
    "    numWeights = len(x_train[0])\n",
    "    weights = np.array([1.0] * numWeights)\n",
    "    for i in range(numWeights):\n",
    "        weights[i] *= random.random()\n",
    "    for i in range(numIterations):\n",
    "        predictions = modelPredict(weights, x_train)\n",
    "        weights = weights - learningRate * (getMeanSquaredGradient(x_train, y_train, predictions))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefac42-62ec-41a2-aef7-c4c82fe8e97d",
   "metadata": {},
   "source": [
    "Here we are trying the model using OpenML's wine quality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b638bd1-f15f-4eef-9e2b-e738c8e7727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2 = oml.datasets.get_dataset(44136)\n",
    "X, Y, _, _ = no2.get_data(target=no2.default_target_attribute, dataset_format='array')\n",
    "X = normalizeData(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9883482d-8b59-463c-9f20-f78618168db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = datasets.fetch_california_housing(return_X_y=True)\n",
    "X = normalizeData(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "560c62b8-7e57-45a5-9cd9-76565f09546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel(x_train, y_train)\n",
    "#after getting familiar enough with numpy to replace most for loops with numpy matrix operations\n",
    "#the amount of time it took this program to train on california_housing went down to seconds\n",
    "\n",
    "#it used to take like 5 minutes to train the program for 1000 iterations\n",
    "#now it takes the program only a few seconds to train for 100,000 iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76a3d11e-a6e9-409e-8b9f-68ba92e2360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.93451831 -1.30095191  1.11288399  0.81892639  1.64622807  2.43127209\n",
      "  2.41980959  6.82786045  2.74634414  0.83613925  5.41946642]\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59f06d19-4e04-499b-9321-ab8dbaaaf52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15775008995284345\n"
     ]
    }
   ],
   "source": [
    "temp = modelPredict(model, x_test)\n",
    "accuracy = calculateAccuracy(y_test, temp)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0af6f33-8372-4d41-904b-41aa5b535b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20255561278017797\n"
     ]
    }
   ],
   "source": [
    "temp = modelPredict(model, x_train)\n",
    "accuracy = calculateAccuracy(y_train, temp)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79e7baf8-6cf8-4d13-a5d8-7d4ac40d7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7cda7f6-3c35-4aac-b121-3c1cb89b1003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5967357176402427"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0862c43-e540-4ca7-96e7-7fae590d03b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
